\documentclass[12pt,oneside]{fithesis2}

% ===== LOADING PACKAGES =====
% language settings, main documnet language last
\usepackage[english]{babel}
% enabling new fonts support (nicer)
\usepackage{lmodern}
% setting input encoding
\usepackage[utf8]{inputenc}
% setting output encoding
\usepackage[T1]{fontenc}
% fithesis2 requires csquotes
\usepackage{csquotes}
% set page margins
\usepackage[top=3.5cm, bottom=3cm, left=2.4cm, right=2.4cm]{geometry}
% package to make bullet list nicer
\usepackage{enumitem}
% math symbols and environments
\usepackage{mathtools}
% packages for complex tables
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{dcolumn}
\usepackage{array}
% enable page rotation
\usepackage{pdflscape}
% generating hyperlinks in document
\usepackage{url}
\usepackage[plainpages=false,pdfpagelabels,colorlinks=true]{hyperref}

% ===== MAIN DOCUMENT SETTINGS =====
% adjusting hyphenation penalties
\tolerance=10000
\hyphenpenalty=500
% space between paragraphs
\setlength{\parskip}{0.6em plus0.2em minus0.2em}
% set correct spacing in itemize
\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
% FI THESIS settings
\thesistitle{Usage of evolvable circuit \\for statistical testing \\of randomness}
\thesissubtitle{Bachelor thesis}
\thesisstudent{Martin Ukrop}
\thesiswoman{false}
\thesisfaculty{fi}
\thesisyear{spring 2013}
\thesisadvisor{RNDr.\ Petr Švenda,\ Ph.D.}
\thesislang{en}

% new commands for results table headers
\newcommand{\m}[1]{\multirow{2}*{#1}}
\newcommand{\rotatedHeader}[2][l]{\rotatebox{90}{\begin{tabular}[#1]{@{}l}#2\end{tabular}}}
\newcommand{\resultsTable}[1]{%
\newcolumntype{C}{>{\centering\arraybackslash}X}%
\begin{tabularx}{\textwidth}{|r*{3}{||S[table-format=2.1]|S[table-format=3.0]|C}|} \hline
\multirow{1}*{\raisebox{-\height-0.3cm}{\rotatebox{90}{\# of rounds}}} & \multicolumn{9}{c|}{IV and key reinitialization} \\ \cline{2-10}
& \multicolumn{3}{c||}{once for run} & 
\multicolumn{3}{c||}{for each test set} & 
\multicolumn{3}{c|}{for each test vector} \\ \cline{2-10}
& \multicolumn{1}{c|}{\rotatedHeader{Dieharder\\(x/20)}} & \multicolumn{1}{c|}{\rotatedHeader{\textsc{Sts Nist}\\(x/162)}} &  \rotatedHeader{EACirc\\(\textsc{aam})}
& \multicolumn{1}{c|}{\rotatedHeader{Dieharder\\(x/20)}} & \multicolumn{1}{c|}{\rotatedHeader{\textsc{Sts Nist}\\(x/162)}} & \rotatedHeader{EACirc\\(\textsc{aam})}
& \multicolumn{1}{c|}{\rotatedHeader{Dieharder\\(x/20)}} & \multicolumn{1}{c|}{\rotatedHeader{\textsc{Sts Nist}\\(x/162)}} & \rotatedHeader{EACirc\\(\textsc{aam})} \\ \hline \hline
#1
\end{tabularx}}

% ===== BEGIN DOCUMENT =====
\begin{document}

\FrontMatter
\ThesisTitlePage

\begin{ThesisDeclaration}
\DeclarationText
\AdvisorName
\end{ThesisDeclaration}

\begin{ThesisThanks}
Thanks will be here.
\end{ThesisThanks}

\begin{ThesisAbstract}
Abstract will be here.
\end{ThesisAbstract}

\begin{ThesisKeyWords}
Keywords will be here.
\end{ThesisKeyWords}

\MainMatter
\tableofcontents
\chapter{Introduction}
\label{chap:intro}
Text ...

\chapter{Statistical randomness testing}
\label{chap:stat-rand-testing}

The goal of randomness testing is to determine, whether the data provided is \textit{random}. 
The problem comes with the definition of randomness, since in truly random data, 
each fixed subsequence (e.\,g. sequence of a hundred zeroes) has the same probability of appearing.
Thus, statistical metrics have been developed to asses the matter of randomness.

All the statistical randomness tests are based on mathematical properties that hold for
\textit{most} of the random sequences with a sufficient length.
A simple example of such property states that in each binary sequence, the number of ones and zeroes should be 
approximately the same. It is crucial to be aware, that this will not hold for \textit{all} sequences (see the example above),
but the probability of randomly generating such sequence sharply decreases when increasing the length of the assessed data.

Randomness testing based on statistical properties of data has its drawbacks and benefits, main of which are discussed below.
\begin{itemize} \rightskip=2em
\item \textbf{Speed}\\
Once the tests are implemented, they do not require excessive amount of time to perform -- 
the data is usually processed once in a linear fashion.
\item \textbf{Universality}\\
Statistical tests can by applied to any binary data regardless of its origin -- they perform equally well. 
This can be viewed both as an advantage and disadvantage, since tests cannot be effortlessly adapted to specific situations.
\item \textbf{One-way design}\\
The creation of new test must be preceded by the idea and analysis of some useful statistical property. This part can be highly 
non-trivial and usually requires a team of skilled mathematicians.
\item \textbf{Results interpretation}\\
The ever-present ambiguity in statistical measurements sometimes makes the results interpretation a highly non-trivial task.
It is crucial to understand what do the results indicate and what they do not. The above-mentioned finite sequence of binary zeroes
fails most of the statistical randomness tests, but its generation is just as probable 
as any other fixed binary sequence of the same length.
Put in another words, even the true random generator may produce non-random looking sequences once in a while.
\end{itemize}

\noindent
In practise, statistical randomness testing is being widely used in fields where the quality of random data is crucial, 
such as cryptography. To ease the assessment process, several statistical randomness testing suites have been developed, 
some of which are discussed below.

\section{Statistical Test Suite by NIST}
\label{sec:sts-nist}

Perhaps the most widely used battery of statistical tests is the Statistical Testing Suite 
by National Institute of Standards and Technology (STS NIST).
The primary motivations for developing this test suite was the need of standardised tests for detecting non-randomness 
in binary (pseudo)random sequences utilized in cryptographic applications. As well as designing the tests,
NIST provides their reference implementation and guidance in their use and application. \cite{web NIST}

The battery consists of 15 different tests, some of which can be run with several parameters. 
For detailed description of the tests, see the original documentation \cite{sts nist documentation}. 
The implementation provided by NIST supports variable input data length and arbitrary number of independent data streams. 
The testing results provide the cumulative p-value of all data streams and the number of passed runs for each test 
according to the set significance level. 
Detailed setting used for the purposes of this thesis can be found in \autoref{sec:settings-statistics}.

\section{Diehard battery of tests}
\label{sec:diehard}

The second, informal, standard of statistical randomness testing is the Diehard Battery of Tests of Randomness, 
developed by George Marsaglia over several years at Florida State University. \cite{diehard website} 
Although now becoming slightly outdated, they were one of the first and most-well known 
in the pioneering years of statistical testing of randomness. 
For long, the Diehard Battery of Tests was considered a golden standard along with STS NIST.

The battery consist of 12 different tests. The original implementation, documentation and tests description are still available,
but since the code has not been revised from its creation in 1995, we chose not to use Marsaglia's original implementation.

\section{Dieharder: A Random Number Test Suite}
\label{sec:dieharder}

Dieharder, as its predecessors, aims to ease the testing of (pseudo)random generators and data for a variety purposes in research 
and cryptography. Developed by Robert G. Brown at the Duke University, it is designed to be as extensible as possible, 
allowing easy implementation of new tests and generators for testing. Most of the tests used allow for 
modifying the default parameters, enabling advanced users to fine-tune the testing process.
According to its creators, it is intended to be the ``Swiss army knife of random number test suite'', 
or if you prefer, ``the last suite you'll ever ware'' for testing random numbers. \cite{dieharder web}

After designing the testing framework, the development team gradually reimplemented and improved the original tests from 
the Diehard Battery of Tests of Randomness (see \autoref{sec:diehard}), 
the tests from STS NIST (see \autoref{sec:sts-nist}) and began to prepare and implement their own new tests.
The suite now contains 31 different tests from various sources. Tests can be run selectively.
The testing results provide the cumulative p-value for each test and a verdict of \textsc{PASS}, \textsc{WEAK} or \textsc{FAIL}
according to the set significance level.
Detailed setting used for the purposes of this thesis can be found in \autoref{sec:settings-statistics}.

\section{Drawbacks of human-designed statistical tests}
\label{sec:limits-stat-testing}

Although convenient in some ways, statistical randomness testing based on human-designed tests has several important drawbacks.
As mentioned above, the test creation must be preceded by an idea of mathematical property and its thorough analysis, 
which can be extremely time- and people-consuming. Further on, the tests are limited to one particular property and
adapting them to specific situation requires beginning the process of test creation all over again.

Both of the above-mentioned problems would be resolved if tests of comparable quality could be generated automatically, without 
the help of human specialists. Such concept and its comparison with human-generated tests is presented in the following chapters.

\chapter{Evolution based randomness testing}
\label{chap:evo-based-testing}

\begin{itemize}
\item introduction, need for other method for randomness testing
\item idea: instead of math analysis we will let program guess the correct analysis for this case
\item advantages will be: no prior math knowledge needed, can potentially discover new metrics fir statistical randomness
\item we will use evolutionary algorithms, namely genetic programming
\end{itemize}

\section{Basic principles of genetic grogramming}
\label{sec:basic-ga}

\begin{itemize}
\item inspired by biology, method of supervised learning
\item we create population of random individuals (solvers)
\item we evaluate fitness of each individual (pre-generated data along with solutions)
\item so called "fitness function" - crucial part!
\item we make crossover among the best (survival of the fittest)
\item we randomly apply "mutation" (to avoid getting stuck in local optimum)
\item we iterate untill desired success rate is achieved
\item points to keep in mind when using GA
\begin{itemize}
\item only tasks with available partial solutions can be used (see next)
\item small change in solver should result in small chenge in fitness
\item designing the fitness function is crucial
\item fine-tuning GA settings (mutation/crossover probability, population size) is important
\end{itemize}
\item generating data with solutions for learning can be computationally expensive
\begin{itemize}
\item possibility to use them multiple times
\item risk of overlearning, individuals might learn to solve this particular instance of problem
\end{itemize}
\end{itemize}

\section{Using software-emulated circuits}
\label{sec:sw-circuits}

\begin{itemize}
\item represent individual in GP as a hardware-like circuit solving the problem
\item circuit has gates with elementary functions and interconnecting wires
\item circuits are emulated by software, internally represented as array of unsigned integers
\item short description of functions
\item it would be sufficient to allow nand only, however more functions improve understandability of evolved circuit for humans, also enables us to limit the circuit to small number of layers and nodes
\item small similarity to neural networks, deep neural netowrks in particular
\end{itemize}

\section{General working principles of EACirc}
\label{sec:eacirc-principles}

\begin{itemize}
\item EACirc is framwork for general problem solving using sw-emulated circuits and EA
\item based on SensorSim developed at LaBAK, FI MUNI, further improved by Matej Pristak and Ondrej Dubovec
\item main modules (+picture):
\begin{itemize}
\item GAlib (MIT), used for evolution
\item project module, used for generating data for supervied learning (test vectors)
\item circuitg emulator, used for running circuits
\item evaluator, used for interpreting circuit outputs and computing fitness of individual circuits
\item set of random generators, needed since computaion is randomized
\item testing files, CATCH
\item help libraries (tinyXML)
\end{itemize}
\item external static checker used for consistency-checking
\end{itemize}

\section{Current capabilities of EACirc}
\label{sec:eacirc-capabilities}

\begin{itemize}
\item old core, basic capabilities of EA provided by GAlib and software emulation taken from work by Matej Pristak, originally from SensorSim
\item main object model has been revised to uitlize the principle of modules, thus enabling integration of multiple projects and evaluators according to actual needs.
\item guaranteed bit-reproducibility now - use of random generators revised, hierarchical system of generators created, any run can be reproduced by providing original input files and one central seed => crucial to experiment verification
\item bit-reproducibility enabled us to implement computation recommencing - EACirc can save and load its complete internal state => useful for computation-expensive experiments (when the machine is rebooted, we can continue from last saved state instead of starting allover again)
\item evolved circuits are exported to 4 different formats (from SensorSim or original work on EACirc?), binary (can be reloaded into EACirc if needed), text and graphical (using Graphviz) (used to ease humal analysis of evolved results) and C source code implementing the circuit (useful for independent verification of circuit work)
\item new static checker created, circumvents most of the EACirc framework (especially circuit emulator), used for static checking on pre-generated test vectors
\item project for distinguishing between eStream cipher output and random stream of data, taken from work by Matej Pristak and slightly revised to operate withing the new object model and allow more detailed configuration
\item project for distinguishing between SHA-3 function output and random stream of data, ideas and hash functions implementations taken from Ondrej Dubovec, gest vector geenration reimplemented from scratch
\item small project for distinguishing among external binary files
\end{itemize}

Most of the code that was taken over was revised and slightly refactor to ease the understanding of its function and to standardise naming and principles used in EACirc. For further details, use and developmetn documentation see EACirc wiki at GitHub.

Note, that EACirc is wider project beyond the scope of this thesis. Some parts were added and/or redesigned in pre process, so not all experiments had all now-supported features. Coinfiguration files may not be compatible across versions, etc.

\chapter{Experiment settings and output data}
\label{chap:settings}

\begin{itemize}
\item introduction - this chapter will describe the settings used in the experiments...
\item our reasons for using these settings
\item description of output files
\item interpretation of result numbers
\end{itemize}

\section{EACirc settings}
\label{sec:settings-eacirc}

\begin{itemize}
\item most of the settings taken from Matej Pristak's thesis (with no optimality verification)
\item GA settings (population size 20, prob mutation 0.05, prob crosover 0.20)
\item 30000 generation with test vector sets changed every 100th generation (thus, 300 unique test sets altogether)
\item circuit - 5 layers, 8 functions in layer, input 16 bytes, output 2 bytes, maximum of 4 connectors (?), all functions allowed except for READX
\item distinguisher - correct output for stream 1 id 0x00, correct for stream 2 is 0xff
\item evaluator - "agent based", each byte is separate output, less or more than 128
\item fitness function = \#(correctly predicted vectors in set)/\#(all vectors in set)
\item 1000 test vectors in each test set
\item only distiguisher experiments, always used 500:500 (according to Matej Pristak, imballance causes test vectors to only guess what type is more frequent in current run)
\item experiment-specific settings described in appropriate section with results
\end{itemize}

\section{EACirc output data}
\label{sec:settings-eacirc-output}

\begin{itemize}
\item main goal: finding strong distinguisher (over 99\% for 50 consecutive generations)
\item displayed average stable generation across 30 independent runs \\
(stable = fitness over $99\%$ for at least next 50 test sets)
\item if none stable generation was found, average average maximum fitness after test vector change is displayed in parentheses.
\end{itemize}

\section{Random data sources}
\label{sec:settings-random}

\begin{itemize}
\item EACirc is randomized algorithm -> need good random data source
\item in most experiments a distinguisher from random data stream is being evolved => crucial to have extremely realiable random data source
\item using quantum random data, generated by measuring quantum effects
\item 2 different sources, HU Berlin, institute in Croatia
\item these 2 sources thoroughly compared, see \autoref{sec:control-germany-croatia}
\end{itemize}

\section{Settings and output data for statistical test batteries}
\label{sec:settings-statistics}

\begin{itemize}
\item to compare our results with existing statistical batteries, statistical randomness of all generated streams was checked using STS NIST and Dieharder
\item 250 MB of data generated for statistical testing, same streams used for both STS NIST and Dieharder
\item STS NIST
\begin{itemize}
\item 100 runs, 100000 bits per run (=> ~11.92 MB used for testing)
\item all tests were run, significance level of ???
\item some runs had problems with tests RandomExcursions and RandomExcursionsVariant, to ensure statistical accuracy of results, these test are ommited in results
\item for each test, following stats are computed:
\begin{itemize}
\item p-value for each run - if this p-value is out of bounds of the interval determined by the significance level, the run is considered failed
\item the number of passed runs is infered
\item the cumullative p-value of all 100 runs
\item if either the cumulative p-value or the number of passed runs for this particular test is out bounds of the interval determined by the significance level, this test is considered as failed
\end{itemize}
\item results expressed as cumullative score for the entire stream, 0 for each failed test, 1 for each passed test. expressed as part of total 162
\end{itemize}
\item Dieharder
\begin{itemize}
\item test corresponding to original Diehard (except for Diehard sums test, due to probable error in test implementation)
\item 1 run of each test, stream length determined by the test itself (comes from design of Dieharder, we want to prevent from revinding the file)
\item total data used for testing: ??? MB (smallest test: ??, biggest test: ??)
\item each test interpreted as PASSED, WEAK or FAILED (significance levels of ???)
\item results for stream again in the form of cumullative score (0 for failed, 0.5 for weak, 1 for passed), out of total 20
\end{itemize}
\end{itemize}

\chapter{Control distinguishers}
\label{chap:distinguish-control}

\begin{itemize}
\item introduction -- the need of reference numbers before analysis
\item we need to define what does it mean "indistinguishable" in our setting
\item we use quantum random data from Humboldt Universitat and Quantum random bit generator service as a standard for randomness
\end{itemize}

\section{Looking for non-randomness in quantum random data}
\label{sec:control-random-random}

\begin{itemize}
\item trying to distinguish quantum random data from quantum random data \\ => we presume to fail
\item using random data from Quantum random bit generator service
\item statistical batteries: data are random (Dieharder: 20/20, STS NIST: 188/188)
\item evolution: no stable distinguisher found, AAM of 0.52 (differences in various runs in 3rd or 4th decimal place)
\item presumption: dependence on test set size and population size
\item presumption confirmed (\autoref{tab:random-set-size-change}), AAM decreases with smaller population and bigger test set size
\end{itemize}

\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.2}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{|c|r||*{6}{C|}} \cline{3-8}
\multicolumn{2}{c||}{} & \multicolumn{6}{c|}{number of test vector in a set} \\ \cline{3-8}
\multicolumn{2}{c||}{} & 200 & 500 & 1000 & 2000 & 5000 & 10\,000 \\ \hline \hline
\multirow{5}*{\rotatedHeader{individuals \\ in population}}
& 5 & -- & -- & (0.509) & - & - & - \\ \cline{2-8}
& 10 & -- & -- & (0.514) & - & - & - \\ \cline{2-8}
& 20 & (0.544) & (0.527) & (0.520) & (0.514) & (0.509) & (0.506) \\ \cline{2-8}
& 50 & - & - & (0.526) & - & - & - \\ \cline{2-8}
& 100 & - & - & (0.530) & - & - & - \\ \hline
\end{tabularx}
\renewcommand{\arraystretch}{1.0}
\caption{Dependence of AAM on population size and test vector set size.}
\label{tab:random-set-size-change}
\end{table}

\section{Distinguishing quantum random data from different sources}
\label{sec:control-germany-croatia}

\begin{itemize}
\item distinguishing streams of quantum random data from Humboldt University and streams of quantum random data from Ruđer Bošković Institute
\begin{itemize}
\item Quantum Random Bit Generator Service, Centre for Informatics and Computing, Ruđer Bošković Institute, Zagreb, Croatia
\item Quantum Random Number Generator Service, Department of Physics, Humboldt University, Berlin, Germany
\end{itemize}
\item 6 files of 5 MB from each source
\item fixed initial reading offsets as (0,0) \\ => same data from given file in each run
\item looking for distinguisher for each pair
\item interpretation of results (\autoref{tab:control-germany-croatia}):
\begin{itemize}
\item data from both sources are equally random for our purposes
\item there is no single statistically different stream in these \\=>they can be used interchangeably 
\end{itemize}
\end{itemize}

\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.2}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{|c|r||*{6}{C|}} \cline{3-8}
\multicolumn{2}{c||}{} & \multicolumn{6}{c|}{QRBG service (Ruđer Bošković Institute, Croatia)} \\ \cline{3-8}
\multicolumn{2}{c||}{} & stream 1 & stream 2 & stream 3 & stream 4 & stream 5 & stream 6 \\ \hline \hline
\multirow{6}*{\rotatedHeader{QRNG service \\(HU, Germany)}}
& stream 1 & (0.521) & (0.520) & (0.520) & (0.519) & (0.519) & (0.519) \\ \cline{2-8}
& stream 2 & (0.158) & (0.519) & (0.520) & (0.520) & (0.520) & (0.519) \\ \cline{2-8}
& stream 3 & (0.519) & (0.522) & (0.519) & (0.520) & (0.519) & (0.519) \\ \cline{2-8}
& stream 4 & (0.520) & (0.520) & (0.519) & (0.518) & (0.519) & (0.519) \\ \cline{2-8}
& stream 5 & (0.519) & (0.520) & (0.519) & (0.518) & (0.520) & (0.520) \\ \cline{2-8}
& stream 6 & (0.520) & (0.519) & (0.520) & (0.520) & (0.519) & (0.519) \\ \hline
\end{tabularx}
\renewcommand{\arraystretch}{1.0}
\caption{Distinguishing binary quantum random streams from independent sources.}
\label{tab:control-germany-croatia}
\end{table}

\section{Uncompressed audio streams}
\label{sec:distinguishing-audio}

\begin{itemize}
\item 12 files
\begin{itemize}
\item 3 quantum random files
\item 3 noise files (white, pink, Brown), generated by SoX
\item 3 noise files via intermediate mp3 compression (2 channels, 16bits, 44.1 kHz => bitrate of 128kbps)
\item noise after 128kbs mp3 compression had ~480 kB
\item 3 samples of transcendental khaoblack metal music
\end{itemize}
\item each file is 30sec of uncompressed WAV audio (5.3MB) (including quantum random files, wav header generated by SoX)
\item evolving distinguisher for each pair
\item interpretation of results (\autoref{tab:uncompressed-audio}):
\begin{itemize}
\item quantum random stream are undistinguishable (we already know)
\item generated white noise is true (undistinguishable from random)
\item pink and Brown noise are different, distinguishable (good result, since pink and Brown noise are generated by filtering white noise and are biased towards lower frequencies)
\item different types of noise can be quite successfully distinguished from one another (generally over 75\%)
\item mp3 compression has small, but detectable effect on the sound (nearly undetectable by unskilled human ear, but successfully shifts the distinguisher success to cca 0.58)
\item comparing noise and mp3 compressed and decompressed noise of the same kind is difficult
\item used metal samples are nearly indistinguishable from each other on the binary level (although the differences are easily detectable by human ear)
\item used metal samples can be reliably distinguished from white noise (which is, in fact only a stream of random data) - general success over 80\%. Less so from pink and Brown noise - general success around 65\%.
\end{itemize}
\item most of the runs have slow rising tendency in fitness \\ => if more generations, the average maximum value might be slightly higher
\end{itemize}

\begin{landscape}
\begin{table}[p]
\centering
\newsavebox{\temp}
\newcolumntype{C}{>{\centering \begin{lrbox}{\temp} \arraybackslash}X<{\end{lrbox} \m{\unhbox\temp} \arraybackslash}}
\begin{tabularx}{22cm}{|c|>{\raggedright\arraybackslash}p{2.5cm}*{4}{||C|C|C}|} \cline{3-14}

\multicolumn{2}{l||}{} & \multicolumn{3}{c||}{random streams} & \multicolumn{3}{c||}{noise (true)} &
\multicolumn{3}{c||}{noise (via mp3)} & \multicolumn{3}{c|}{metal music} \\ \cline{3-14}

\multicolumn{2}{l||}{} &  
\multicolumn{1}{c|}{\rotatedHeader{random\\stream 1}} & 
\multicolumn{1}{c|}{\rotatedHeader{random\\stream 2}} & 
\multicolumn{1}{c||}{\rotatedHeader{random\\stream 3}} & 
\multicolumn{1}{c|}{\rotatedHeader{white noise}} & 
\multicolumn{1}{c|}{\rotatedHeader{pink noise}} & 
\multicolumn{1}{c||}{\rotatedHeader{Brown noise}} & 
\multicolumn{1}{c|}{\rotatedHeader{white noise\\(via mp3)}} & 
\multicolumn{1}{c|}{\rotatedHeader{pink noise\\(via mp3)}} & 
\multicolumn{1}{c||}{\rotatedHeader{brown noise\\(via mp3)}} & 
\multicolumn{1}{c|}{\rotatedHeader{metal music\\(sample 1)}} & 
\multicolumn{1}{c|}{\rotatedHeader{metal music\\(sample 2)}} & 
\multicolumn{1}{c|}{\rotatedHeader{metal music\\(sample 3)}} \\ \cline{3-14} \hline \hline

\multirow{3}{*}[-20pt]{\rotatedHeader{random}} &
random stream 1 & 
n/a & (0.52) & (0.52) & (0.52) & (0.80) & (0.84) & (0.59) & (0.93) & (0.89) & (0.84) & (0.87) & (0.83) \\ \cline{2-14}
& random stream 2 &
(0.52) & n/a & (0.52) & (0.52) & (0.83) & (0.83) & (0.57) & (0.82) & (0.84) & (0.90) & (0.85) & (0.82) \\ \cline{2-14}
& random stream 3 & 
(0.52) & (0.52) & n/a & (0.52) & (0.94) & (0.91) & (0.58) & (0.83) & (0.83) & (0.89) & (0.83) & (0.85) \\ \hline \hline
\multirow{3}{*}[-10pt]{\rotatedHeader{noise (true)}} & 
white noise (true) &
(0.52) & (0.52) & (0.52) & n/a & (0.83) & (0.81) & (0.59) & (0.87) & (0.89) & (0.86) & (0.93) & (0.81) \\ \cline{2-14}
& pink noise (true) &
(0.80) & (0.83) & (0.94) & (0.83) & n/a & (0.76) & (0.86) & (0.52) & (0.76) & (0.65) & (0.65) & (0.66) \\ \cline{2-14}
& Brown noise (true) &
(0.84) & (0.83) & (0.91) & (0.81) & (0.76) & n/a & (0.86) & (0.76) & (0.56) & (0.71) & (0.69) & (0.68) \\ \hline \hline
\multirow{3}{*}[-10pt]{\rotatedHeader{noise (mp3)}} & 
white noise (via mp3) &
(0.59) & (0.57) & (0.58) & (0.59) & (0.86) & (0.86) & n/a & (0.91) & (0.83) & (0.84) & (0.80) & (0.78) \\ \cline{2-14}
& pink noise (via mp3) &
(0.93) & (0.82) & (0.83) & (0.87) & (0.52) & (0.76) & (0.91) & n/a & (0.78) & (0.63) & (0.68) & (0.70) \\ \cline{2-14}
& Brown noise (via mp3) &
(0.89) & (0.84) & (0.83) & (0.89) & (0.76) & (0.56) & (0.83) & (0.78) & n/a & (0.71) & (0.69) & (0.67) \\ \hline \hline
\multirow{3}{*}[-5pt]{\rotatedHeader{metal music}} & 
metal music (sample 1) &
(0.84) & (0.90) & (0.89) & (0.86) & (0.65) & (0.71) & (0.84) & (0.63) & (0.71) & n/a & (0.54) & (0.56) \\ \cline{2-14}
& metal music (sample 2) &
(0.87) & (0.85) & (0.83) & (0.93) & (0.65) & (0.69) & (0.80) & (0.68) & (0.69) & (0.54) & n/a & (0.53) \\ \cline{2-14}
& metal music (sample 3) &
(0.83) & (0.82) & (0.85) & (0.81) & (0.66) & (0.68) & (0.78) & (0.70) & (0.67) & (0.56) & (0.53) & n/a \\ \cline{1-14}
\end{tabularx}
\caption{Distinguishing random streams and uncompressed audio (noise, compressed noise, metal music).}
\label{tab:uncompressed-audio}
\end{table}
\end{landscape}

\chapter{Distinguishing cipher outputs from random stream}
\label{chap:distinguish-cipher}

\begin{itemize}
\item introduction, idea, running EACirc along with statistical batteries
\item stream ciphers from eStream competition
\end{itemize}

\section{Stream ciphers used}
\label{sec:estream-ciphers}

\begin{itemize}
\item ciphers except for ?? (why??)
\item from last phase
\item those that could be limited in rounds are tested in weaker variant as well
\item differences from Metej Pristak thesis
\end{itemize}

\section{Generating binary stream from stream ciphers}
\label{sec:estream-settings}

\begin{itemize}
\item cipher modes (iv+key initialization frequency)
\item case of LEX (not weakening the cipher, only making shorter output)
\item case of TSC (producing binary stream of 0 for 1-8 rounds) => problems in 3 Dieharder tests
\end{itemize}

\section{Results interpretation}
\label{sec:estream-results}

\begin{itemize}
\item ???
\item more or less as statistical batteries
\item dieharder better in some case than STS-NIST (is newer and some tests are redesigned)
\item statistical tests has much more input data compared to EACirc
\item using evolved distinguisher is quick
\end{itemize}

\begin{table}[htb]
\centering
\resultsTable{
1 & 0.0 & 0 & $n=2681$ & 0.0 & 0 & (0.85) & 0.0 & 5 & $n=1431$ \\ \hline
2 & 0.5 & 0 & (0.54) & 1.0 & 0 & (0.54) & 15.5 & 146 & (0.52) \\ \hline
3 & 1.0 & 0 & (0.53) & 1.0 & 0 & (0.53) & 15.0 & 160 & (0.52) \\ \hline
4 & 3.5 & 79 & (0.52) & 3.0 & 78 & (0.52) & 20.0 & 160 & (0.52) \\ \hline
5 & 4.5 & 79 & (0.52) & 3.5 & 91 & (0.52) & 17.5 & 161 & (0.52) \\ \hline
6 & 19.0 & 158 & (0.52) & 19.0 & 159 & (0.52) & 18.0 & 162 & (0.52) \\ \hline
7 & 18.5 & 162 & (0.52) & 19.0 & 161 & (0.52) & 20.0 & 161 & (0.52) \\ \hline \hline
8 & 20.0 & 162 & (0.52) & 20.0 & 159 & (0.52) & 19.0 & 161 & (0.52) \\ \hline
}
\caption{Random distinguishers for Decim ciphertext.}
\label{tab:estream-decim}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1 & 20.0 & 162 & (0.52) & 20.0 & 161 & (0.52) & 18.0 & 162 & (0.52) \\ \hline \hline
4 & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) \\ \hline
}
\caption{Random distinguishers for FUBUKI ciphertext.}
\label{tab:estream-fubuki}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1 & 0.0 & 0 & $n=221$ & 0.0 & 0 & (0.67) & 18.5 & 162 & (0.52) \\ \hline
2 & 0.0 & 0 & $n=471$ & 0.5 & 0 & (0.66) & 20.0 & 162 & (0.52) \\ \hline
3 & 19.5 & 160 & (0.52) & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) \\ \hline \hline
13 & 20.0 & 162 & (0.52) & 20.0 & 161 & (0.52) & 19.5 & 162 & (0.52) \\ \hline
}
\caption{Random distinguishers for Grain ciphertext.}
\label{tab:estream-grain}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1 & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) \\ \hline \hline
10 & 20.0 & 160 & (0.52) & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) \\ \hline
}
\caption{Random distinguishers for Hermes ciphertext.}
\label{tab:estream-hermes}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1 & 0.0 & 0 & $n=148$ & 0.0 & 0 & $n=7274$ & 3.0 & 1 & $n=154$ \\ \hline
2 & 4.0 & 1 & $n=221$ & 4.0 & 1 & $n=304$ & 3.5 & 1 & $n=254$ \\ \hline
3 & 0.5 & 1 & $n=378$ & 3.5 & 1 & $n=491$ & 4.0 & 1 & $n=361$ \\ \hline
4 & 20.0 & 162 & (0.52) & 19.5 & 162 & (0.52) & 20.0 & 161 & (0.52) \\ \hline \hline
10 & 19.5 & 162 & (0.52) & 19.5 & 160 & (0.52) & 20.0 & 160 & (0.52) \\ \hline
}
\caption{Random distinguishers for LEX ciphertext.}
\label{tab:estream-lex}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1 & 5.5 & 1 & (0.87) & 8.5 & 1 & (0.67) & 17.5 & 161 & (0.52) \\ \hline
2 & 5.5 & 1 & (0.87) & 7.0 & 1 & (0.67) & 19.5 & 162 & (0.52) \\ \hline
3 & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) & 19.5 & 161 & (0.52) \\ \hline \hline
12 & 20.0 & 162 & (0.52) & 19.5 & 161 & (0.52) & 19.0 & 161 & (0.52) \\ \hline
}
\caption{Random distinguishers for Salsa20 ciphertext.}
\label{tab:estream-salsa}
\end{table}

\begin{table}[htb]
\centering
\resultsTable{
1--8 & 0.0${}^{*}$ & 0 & $n=104$ & 0.0${}^{*}$ & 0 & $n=101$ & 0.0${}^{*}$ & 0 & $n=104$ \\ \hline
9 & 1.0 & 1 & $n=234$ & 1.5 & 1 & $n=491$ & 2.0 & 1 & $n=121$ \\ \hline
10 & 2.0 & 13 & $n=188$ & 3.0 & 13 & $n=218$ & 3.0 & 12 & $n=158$ \\ \hline
11 & 10.0 & 157 & (0.52) & 11.5 & 157 & (0.52) & 14.0 & 159 & (0.52) \\ \hline
12 & 16.0 & 162 & (0.52) & 17.0 & 161 & (0.52) & 17.5 & 162 & (0.52) \\ \hline
13 & 20.0 & 162 & (0.52) & 20.0 & 162 & (0.52) & 19.0 & 162 & (0.52) \\ \hline \hline
32 & 20.0 & 161 & (0.52) & 20.0 & 162 & (0.52) & 20.0 & 161 & (0.52) \\ \hline
}
\caption{Random distinguishers for TSC-4 ciphertext.}
\label{tab:estream-tsc}
\end{table}

\chapter{Analysis of Salsa20 output stream}
\label{chap:analysis-salsa}
\begin{itemize}
\item learns current vectors quicker than other ciphers
\item the case of six
\end{itemize}

\chapter{Distinguishing hash outputs from random stream}
\label{chap:distinguish-hash}

\begin{itemize}
\item introduction, idea
\item hash function candidates from SHA-3
\end{itemize}

\section{Hash functions used}
\label{sec:hash-functions}

\begin{itemize}
\item except for 2 (?? source code size, compilation)
\item from last phase
\item those that could be limited in rounds are tested in weaker variant as well
\item differences from Ondrej Dubovec Bc thesis
\end{itemize}

\section{Generating binary stream from hash functions}
\label{sec:hash-settings}

\begin{itemize}
\item length set to 256b
\item hashing 4 byte counters starting from random value (in fact, cutting each hash in half)
\end{itemize}

\section{Determining optimal set change frequency}
\label{sec:hash-set-change-freqency}

\begin{itemize}
\item previously,we used change every 100 generations
\item 100 was taken from Matej Pristak's thesis
\item Ondrej proposes 10 as best, however, data is not provided
\item interpretation of results (\autoref{tab:hash-set-change-freqency}):
\begin{itemize}
\item ???
\end{itemize}
\end{itemize}

\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.2}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{2cm}||*{8}{C|}} \cline{2-9}
\multicolumn{1}{l||}{} & \multicolumn{8}{c|}{change frequency for test vector set} \\ \cline{2-9}
\multicolumn{1}{l||}{} & 5 & 10 & 20 & 50 & 100 & 200 & 500 & 1000 \\ \hline \hline
30\,000 g. & (0.614) & (0.614) & (0.607) & (0.602) & (0.599) & (0.598) & (0.591) & (0.582) \\ \hline
run-time & 70 m. & 52 m. & 42 m. & 37 m. & 32 m. & 28 m. & 23 m. & 20 m. \\ \hline \hline
300 sets & (0.567) & (0.583) & (0.585) & (0.589) & (0.599) & (0.608) & (0.617) & (0.618) \\ \hline
run-time & 4 m. & 6 m. & 9 m. & 19 m. & 32 m. & 57 m. & 115 m. & 220 m. \\ \hline
\end{tabularx}
\renewcommand{\arraystretch}{1.0}
\caption{Determining optimal change frequency for test vector set.}
\label{tab:hash-set-change-freqency}
\end{table}

\section{Results interpretation}
\label{sec:hash-results}

\begin{itemize}
\item ???
\end{itemize}

\begin{table}[htb]
\centering
%\renewcommand{\arraystretch}{1.2}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{2cm}||*{8}{C|}} \cline{2-9}
\multicolumn{1}{l||}{} & \multicolumn{8}{c|}{number of rounds} \\ \cline{2-9}
\multicolumn{1}{l||}{} & 0 & 1 & 2 & 3 & 4 & 5 & 6 & full \\ \hline \hline
ARIRANG & $n=694$ & $n=707$ & $n=467$ & $n=1071$ & (full) & -- & -- & (0.52) \\ \hline
Aurora & $n=5614$ & (0.75) & (0.78) !!! & (0.52) & -- & -- & -- & (0.52) \\ \hline
Blake & $n=474$ & (0.52) & -- & -- & -- & -- & -- & (0.52) \\ \hline
Blue Midnight Wish & (0.52) & -- & -- & -- & -- & -- & -- & (0.52) \\ \hline
Cheetah & $n=181$ & $n=574$ & $n=708$ & (0.90) !!! & (0.86)!!! & (0.52) & -- & (0.52) \\ \hline
CHI & (0.52) & -- & -- & -- & -- & -- & -- & (0.52) \\ \hline
CRUNCH & $n=104$ & $n=534$ & $n=954$ & 10-$n=1327$ & 17-$n=774$ & 34-(0.52) & & (0.52) \\ \hline
CubeHash & $n=104$ & (0.52) & -- & -- & -- & -- & -- & (0.52) \\ \hline
DCH & $n=104$ & (0.73) !!! & (0.52) & -- & -- & -- & -- & (0.52) \\ \hline
Dynamic SHA & $n=484$ & $n=2337$ & $n=1773$ !!! & (0.95) !!! & (0.74) & (0.61) & (0.59) & (0.52) \\ \hline
Dynamic SHA2 & -- & (0.94) !!! & (0.74) & (0.75) & (0.57) & (0.60) & & (0.52) \\ \hline
\end{tabularx}
%\renewcommand{\arraystretch}{1.0}
\caption{Random distinguishers for SHA-3 candidate functions.}
\label{tab:hash-distinguishers}
\end{table}

\chapter{Conclusions and future work}
\label{chap:conclusions}



\section{Conclusions based on experimental data}
\label{sec:outro-conclusions}

\begin{itemize}
\item summary of what we did
\item control distinguishers (random-random, hr-de, audio)
\item estream (round limited ciphers)
\item analysis of Salsa20
\item sha3 (round limited hash functions)
\end{itemize}

\begin{itemize}
\item different approach than statistical batteries -> possibly new things
\item dynamically adapting distinguisher - both advantage and disadvantage
\item comparable to statistical tests, however smaller inputs
\item speed: slow learning (more computational power needed), fast distinguishing
\item problem with interpreting results
\end{itemize}

\section{Proposed future work}
\label{sec:outro-future-work}

\begin{itemize}
\item deep analyses instead of wide
\item possibilities of longer input 
\begin{itemize}
\item READX
\item memory circuit
\end{itemize}
\item tools for interpreting results
\begin{itemize}
\item histogram of outputs in nodes
\end{itemize}
\item fixing functions in layers
\end{itemize}

\end{document}
